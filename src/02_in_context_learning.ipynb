{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# In-context learning with Hugging Face\n",
        "\n",
        "We will explore the capabilities of open-source transformer-based models in the task of in-context learning."
      ],
      "metadata": {
        "id": "7u_9qhFBbGTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet\n",
        "!pip install torch --quiet"
      ],
      "metadata": {
        "id": "Y2qDRjFCbvWl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all necessary libraries."
      ],
      "metadata": {
        "id": "74rkPqzQcMRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig"
      ],
      "metadata": {
        "id": "IBQzImBLb-EU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load a pretrained model. We can experiment with varius models and model sizes: https://huggingface.co/google."
      ],
      "metadata": {
        "id": "xUF1VHP0evrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='google/flan-t5-large'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "j7Fm7QTqcWqp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ],
      "metadata": {
        "id": "grPw5gH8cbsM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot learning\n",
        "\n",
        "Let's start with prompt encoding."
      ],
      "metadata": {
        "id": "uLwH2At4fFWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "What is the capital of Germany?\n",
        "\"\"\"\n",
        "\n",
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "tokens = sentence_encoded['input_ids']\n",
        "\n",
        "print (tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h0IdzgEcgsb",
        "outputId": "da6447a6-1c56-4188-ba94-d0ec4e1bd01a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 363,   19,    8, 1784,   13, 3434,   58,    3,    1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can print out actual tokens."
      ],
      "metadata": {
        "id": "wozcOpfBgPs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(tokens[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4IzbZ4mflsX",
        "outputId": "2cf6eac3-4c58-4c52-c7c9-dd084d4c2ee9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁What', '▁is', '▁the', '▁capital', '▁of', '▁Germany', '?', '▁', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = model.generate(tokens, max_new_tokens=50)\n",
        "\n",
        "output = tokenizer.decode(completion[0], skip_special_tokens=True)\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwmZzKv0r4IM",
        "outputId": "58d2162f-9638-489f-a3ba-d61d2583f950"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "berlin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-shot learning\n",
        "It is not exactly what we wanted. Let's provide the model with one example."
      ],
      "metadata": {
        "id": "hRFoNvrAaXXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"What is the capital of France?\n",
        "The capital of France is Paris.\n",
        "\n",
        "What is the capital of Germany?\n",
        "\"\"\"\n",
        "\n",
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')"
      ],
      "metadata": {
        "id": "34uYuFO9GgTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "tokens = sentence_encoded['input_ids']"
      ],
      "metadata": {
        "id": "5KH-Jwwxa1EB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = model.generate(tokens, max_new_tokens=50)\n",
        "\n",
        "output = tokenizer.decode(completion[0], skip_special_tokens=True)\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "id": "hHRCDPNAa-dm",
        "outputId": "cbbc3d5d-d6d6-4ac0-91d1-674e57f6e443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Berlin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-shot learning\n",
        "It's better, but we want to receive the answer in the form of a complete sentence. Let's provide the model with one more example."
      ],
      "metadata": {
        "id": "zGkg9S1bavrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"What is the capital of France?\n",
        "The capital of France is Paris.\n",
        "\n",
        "What is the capital of Spain?\n",
        "The capital of Spain is Madrid.\n",
        "\n",
        "What is the capital of Germany?\n",
        "\"\"\"\n",
        "\n",
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')"
      ],
      "metadata": {
        "id": "q6NU9L5GayvH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_encoded = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "tokens = sentence_encoded['input_ids']"
      ],
      "metadata": {
        "id": "hx0wqX2AbN8f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = model.generate(tokens, max_new_tokens=50)\n",
        "\n",
        "output = tokenizer.decode(completion[0], skip_special_tokens=True)\n",
        "\n",
        "print (output)"
      ],
      "metadata": {
        "id": "1cT0Kox3bOyq",
        "outputId": "07949c26-7320-4f64-d059-386534d79a99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Germany is Berlin.\n"
          ]
        }
      ]
    }
  ]
}