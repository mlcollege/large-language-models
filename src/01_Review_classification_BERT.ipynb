{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "01-Review-classification-BERT.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2G72AoRPWf_"
      },
      "source": [
        "# Travel agency's reviews - classification with BERT\n",
        "\n",
        "Implement and evaluate a classifier of user reviews with BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMvNNQdV5BDM"
      },
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1FP7beWPWgE"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv('https://raw.githubusercontent.com/mlcollege/natural-language-processing/master/data/en_reviews.csv', sep='\\t', header=None, names =['rating', 'text'])\n",
        "reviews[35:45]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSN587NSPWgN"
      },
      "source": [
        "## Preparation of train and test data sets\n",
        "Separate and rename target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhdXlx4PWhT"
      },
      "source": [
        "target = reviews['rating']\n",
        "data = reviews['text']\n",
        "\n",
        "print(data[:5])\n",
        "print(target[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a2lU0UiX-zc"
      },
      "source": [
        "Import the BERT model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRUQWLcQX90M"
      },
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDVh-XgC43ig"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l75NGHcPdPPO"
      },
      "source": [
        "Split the data to train and test parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q26njNEM43zJ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.1)\n",
        "print('Train size: {}'.format(len(X_train)))\n",
        "print('Test size: {}'.format(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3c1mVpZdsyC"
      },
      "source": [
        "Tokenize the documents and create attention masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOksVWVa44BY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "train_ids=[]\n",
        "train_masks=[]\n",
        "test_ids=[]\n",
        "test_masks=[]\n",
        "\n",
        "\n",
        "for doc in X_train:\n",
        "    bert_inp = bert_tokenizer.encode_plus(doc, add_special_tokens = True, pad_to_max_length = True, max_length = 64, return_attention_mask = True)\n",
        "    train_ids.append(np.array(bert_inp['input_ids']))\n",
        "    train_masks.append(np.array(bert_inp['attention_mask']))\n",
        "\n",
        "for doc in X_test:\n",
        "    bert_inp = bert_tokenizer.encode_plus(doc, add_special_tokens = True, pad_to_max_length = True, max_length = 64, return_attention_mask = True)\n",
        "    test_ids.append(np.array(bert_inp['input_ids']))\n",
        "    test_masks.append(np.array(bert_inp['attention_mask']))\n",
        "\n",
        "train_ids = np.asarray(train_ids)\n",
        "train_masks = np.asarray(train_masks)\n",
        "test_ids = np.asarray(test_ids)\n",
        "test_masks = np.asarray(test_masks)\n",
        "\n",
        "print (train_ids.shape)\n",
        "print (test_ids.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYi7wxDkd-tp"
      },
      "source": [
        "One-hot encode the target values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKNCMIf_eC7o"
      },
      "source": [
        "from tensorflow.python.keras.utils import np_utils\n",
        "\n",
        "n_classes = 5\n",
        "y_train = np_utils.to_categorical(y_train-1, n_classes)\n",
        "y_test = np_utils.to_categorical(y_test-1, n_classes)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOhafchep75"
      },
      "source": [
        "Compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeVba9Zl44Ov"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = Adam(learning_rate=2e-5, epsilon=1e-08)\n",
        "bert_model.compile(loss=loss,optimizer = optimizer,metrics=[\"accuracy\"])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpB2shP6aRfv"
      },
      "source": [
        "bert_model.fit([train_ids, train_masks], y_train, batch_size=32, epochs=3, validation_data=([test_ids, test_masks], y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6lPhMbPiTXj"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcMCFzp8aR5V"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = bert_model.predict([test_ids, test_masks])\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "y_pred_class = np.argmax(y_pred[0], axis=1)\n",
        "\n",
        "print (\"Test accuracy: {:.4f}\".format(accuracy_score(y_test_class, y_pred_class)))\n",
        "print ()\n",
        "print(metrics.classification_report(y_test_class, y_pred_class, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}